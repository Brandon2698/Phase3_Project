{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTING CUSTOMER CHURN FOR SyriaTel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "The business problem at hand is the need to predict customer churn accurately. By identifying potential churners early on, SyriaTel can implement targeted strategies to retain customers, such as offering incentives, personalized promotions, or improved customer service. This proactive approach can significantly impact customer retention rates and, consequently, the overall financial health of the company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Business Understanding\n",
    "\n",
    "The primary stakeholder for this project is SyriaTel, a telecommunications company. SyriaTel is interested in understanding and predicting customer churn, which refers to the phenomenon where customers discontinue their services with the company. This is a critical concern for SyriaTel, as retaining customers is crucial for sustaining revenue and ensuring long-term business success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "Classification is a suitable approach for this problem context due to the nature of the target variable, which is 'churn.' Churn is typically a binary outcome â€“ a customer either churns (1) or does not churn (0). Therefore, the problem naturally fits into the framework of binary classification, where the goal is to categorize customers into two classes based on certain features.\n",
    "\n",
    "The objective is to build a predictive model that can classify customers as potential churners or non-churners. This model will be trained on historical data, leveraging patterns and relationships between various customer-related features and the likelihood of churn. Classification algorithms, such as logistic regression, decision trees, or support vector machines, are well-suited for this task as they are designed to handle binary outcomes and can provide probability estimates for each class.\n",
    "\n",
    "By employing classification techniques, SyriaTel can make informed and timely decisions to implement retention strategies, ultimately reducing customer churn and fostering long-term customer relationships. This predictive approach aligns with modern data-driven business practices, allowing SyriaTel to be proactive in addressing customer satisfaction and loyalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data Preparation\n",
    "Handle Missing Data: Address any missing values in the dataset.\n",
    "Deal with Non-numeric Data: Convert categorical data into numeric format.\n",
    "Prevent Data Leakage: Ensure proper separation of training and testing data.\n",
    "Scale Data (if applicable): If using distance-based models, scale the data.\n",
    "Feature Engineering (optional): Create new features if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"SyriaTel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data types of all the columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numerical\n",
    "label_encoder = LabelEncoder()\n",
    "df['international plan'] = label_encoder.fit_transform(df['international plan'])\n",
    "df['voice mail plan'] = label_encoder.fit_transform(df['voice mail plan'])\n",
    "\n",
    "# Convert boolean churn column to 0 and 1\n",
    "df['churn'] = df['churn'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data types of all the columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-predictive columns\n",
    "df = df.drop(['state', 'phone number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Extract correlations with the 'churn' column\n",
    "churn_correlations = correlation_matrix['churn'].sort_values(ascending=False)\n",
    "\n",
    "# Display the correlations\n",
    "print(churn_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "International plan, customer service calls, total day minutes and total day charge seem to have the highest positive correlation with churn.\n",
    "\n",
    "Total intl calls, number vmail messages and voicemail plan have the only negative correlation with churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling, splitting and training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign 'churn' to y and drop it from the dataframe\n",
    "X = df.drop('churn', axis=1)  \n",
    "y = df['churn']\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform using MinMaxScaler\n",
    "df = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(random_state=42)\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log_reg)}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"\\nRandom Forest Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf)}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Support Vector Machine (SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "print(\"\\nSupport Vector Machine Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm)}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. K-Nearest Neighbors (KNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_knn)}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 5. Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "print(\"\\nDecision Tree Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dt)}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['log_reg_model','Random Forest', 'svm_model', 'knn_model', 'dt_model']\n",
    "predictions = [y_pred_log_reg, y_pred_rf, y_pred_svm, y_pred_knn, y_pred_dt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Confusion Matrix Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(len(models)):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    cm = confusion_matrix(y_test, predictions[i])\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.title(f'Confusion Matrix - {models[i]}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ROC Curve Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(models)):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predictions[i].predict_proba(X_test)[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{models[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Importance Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(models)):\n",
    "    if 'Random Forest' in models[i]:  \n",
    "        feature_importances = pd.Series(models[i].feature_importances_, index=X.columns)\n",
    "        feature_importances.nlargest(10).plot(kind='barh', label=models[i])\n",
    "\n",
    "plt.title('Top 10 Feature Importance Comparison - Random Forest')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Precision-Recall Curve Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(models)):\n",
    "    precision, recall, _ = precision_recall_curve(y_test, predictions[i].predict_proba(X_test)[:,1])\n",
    "    plt.plot(recall, precision, label=models[i])\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Comparison - Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [accuracy_score(y_test, pred) for pred in predictions]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(models, accuracies, color=['blue', 'green', 'red', 'purple', 'orange'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Comparison - Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(classifier, 'churn_classifier_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
